{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AstraForge Toolkit \u2014 Local API smoke test\n",
        "\n",
        "Quick sanity checks for the published package against a locally running AstraForge API, plus the same quick-start snippets from the README.\n",
        "\n",
        "Prereqs:\n",
        "- Backend running at `http://localhost:8000` (e.g., `make backend-serve`)\n",
        "- An API key (create via the in-app API Keys screen or `/api/api-keys/`)\n",
        "- Package installed (`pip install -e ../astraforge-python-package` or from PyPI)\n",
        "- For the DeepAgent example, set `OPENAI_API_KEY` (or configure your preferred model) so LangChain can call a chat model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the local package in editable mode (run from the examples/ folder)\n",
        "%pip install -e .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "BASE_URL = \"http://localhost:8000/api\"\n",
        "API_KEY = os.getenv(\"ASTRA_FORGE_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a sandbox session (no DeepAgent conversation)\n",
        "Use the sandbox API directly without creating a DeepAgent conversation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from astraforge_toolkit import DeepAgentClient\n",
        "\n",
        "client = DeepAgentClient(base_url=BASE_URL, api_key=API_KEY)\n",
        "sandbox_session = client.create_sandbox_session()\n",
        "SANDBOX_SESSION_ID = sandbox_session.session_id\n",
        "print(f\"Sandbox session: {SANDBOX_SESSION_ID} (workspace: {sandbox_session.workspace_path})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload and read sandbox files\n",
        "Use the helper methods on `DeepAgentClient` to push a file into the sandbox and fetch it back.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload text (or bytes) to the sandbox workspace\n",
        "upload_result = client.upload_file(\n",
        "    SANDBOX_SESSION_ID,\n",
        "    \"/workspace/hello_from_notebook.txt\",\n",
        "    content=\"hello from the notebook!\\n\",\n",
        ")\n",
        "upload_result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the file back; set encoding=None to get raw bytes\n",
        "downloaded = client.get_file_content(\n",
        "    SANDBOX_SESSION_ID,\n",
        "    \"/workspace/hello_from_notebook.txt\",\n",
        "    encoding=\"utf-8\",\n",
        ")\n",
        "print(downloaded)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a sandbox-backed DeepAgent (README quick start)\n",
        "This creates a DeepAgent conversation (separate from the standalone sandbox session above) and reuses its sandbox across tool calls.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install a model provider helper for the example (skip if already installed)\n",
        "%pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from deepagents import create_deep_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from astraforge_toolkit import (\n",
        "    SandboxBackend,\n",
        "    sandbox_shell,\n",
        "    sandbox_python_repl,\n",
        "    sandbox_open_url_with_playwright,\n",
        "    sandbox_view_image,\n",
        ")\n",
        "\n",
        "conv = client.create_conversation()\n",
        "AGENT_THREAD_ID = conv.conversation_id\n",
        "AGENT_SANDBOX_SESSION_ID = conv.sandbox_session_id\n",
        "print(f\"Using DeepAgent conversation {AGENT_THREAD_ID} and sandbox {AGENT_SANDBOX_SESSION_ID} for tool calls\")\n",
        "\n",
        "def backend_factory(rt):\n",
        "    return SandboxBackend(\n",
        "        rt,\n",
        "        base_url=BASE_URL,\n",
        "        api_key=API_KEY,\n",
        "        session_id=AGENT_SANDBOX_SESSION_ID,\n",
        "        # optional: session_params={\"image\": \"astraforge/codex-cli:latest\"},\n",
        "    )\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\")  # or any chat model you prefer\n",
        "tools = [\n",
        "    sandbox_shell,\n",
        "    sandbox_python_repl,\n",
        "    sandbox_open_url_with_playwright,\n",
        "    sandbox_view_image,\n",
        "]\n",
        "\n",
        "deep_agent = create_deep_agent(\n",
        "    model=model,\n",
        "    backend=backend_factory,\n",
        "    tools=tools,\n",
        ")\n",
        "\n",
        "RUN_CONFIG = {\n",
        "    \"thread_id\": AGENT_THREAD_ID,\n",
        "    \"configurable\": {\"sandbox_session_id\": AGENT_SANDBOX_SESSION_ID},\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='List files in /workspace', additional_kwargs={}, response_metadata={}, id='3b7731d6-1dc4-4f65-bb3b-ac7f723cbcab'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 4505, 'total_tokens': 4520, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4480}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_67cf3fed12', 'id': 'chatcmpl-CheGx2frlTZlAF6beEx4JLZvmem1M', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--3c589a20-7a1b-4586-a05c-336240e8c640-0', tool_calls=[{'name': 'ls', 'args': {'path': '/workspace'}, 'id': 'call_Jhk89EX4xvn4eLtYUDyXBtOX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4505, 'output_tokens': 15, 'total_tokens': 4520, 'input_token_details': {'audio': 0, 'cache_read': 4480}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content=\"['/workspace/.', '/workspace/..', '/workspace/hello.txt']\", name='ls', id='eaf35d82-079f-41c8-a7c0-4fce46010a3a', tool_call_id='call_Jhk89EX4xvn4eLtYUDyXBtOX'),\n",
              "  AIMessage(content='The files in the `/workspace` directory are:\\n- `hello.txt`', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 4543, 'total_tokens': 4559, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4480}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_50906f2aac', 'id': 'chatcmpl-CheGzjFXSEdT8rGXr9hUMxn2lmpIH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--4d63bf71-64e1-4a0d-a5c9-67c1547a92bf-0', usage_metadata={'input_tokens': 4543, 'output_tokens': 16, 'total_tokens': 4559, 'input_token_details': {'audio': 0, 'cache_read': 4480}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "deep_agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"List files in /workspace\"}]},\n",
        "    config=RUN_CONFIG,\n",
        ")\n",
        "\n",
        "# Reuse RUN_CONFIG for follow-up calls to keep the same sandbox session and thread ID."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}