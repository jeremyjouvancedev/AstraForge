{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AstraForge Toolkit â€” Local API smoke test\n",
        "\n",
        "Quick sanity checks for the published package against a locally running AstraForge API, plus the same quick-start snippets from the README.\n",
        "\n",
        "Prereqs:\n",
        "- Backend running at `http://localhost:8001` (e.g., `make backend-serve`)\n",
        "- An API key (create via the in-app API Keys screen or `/api/api-keys/`)\n",
        "- Package installed (`pip install -e ../astraforge-python-package` or from PyPI)\n",
        "- For the DeepAgent example, set `OPENAI_API_KEY` (or configure your preferred model) so LangChain can call a chat model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the local package in editable mode (run from the examples/ folder)\n",
        "%pip install -e .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "BASE_URL = os.getenv(\"ASTRA_FORGE_API_URL\")\n",
        "API_KEY = os.getenv(\"ASTRA_FORGE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging, sys\n",
        "\n",
        "# Emit sandbox debug logs only for AstraForge backends\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s %(levelname)s [%(name)s] %(message)s',\n",
        "    stream=sys.stdout,\n",
        "    force=True,\n",
        ")\n",
        "logging.getLogger('astraforge_toolkit').setLevel(logging.DEBUG)\n",
        "logging.getLogger('astraforge.sandbox').setLevel(logging.DEBUG)\n",
        "# Quiet noisy libraries\n",
        "logging.getLogger('openai').setLevel(logging.WARNING)\n",
        "logging.getLogger('httpx').setLevel(logging.WARNING)\n",
        "logging.getLogger('urllib3').setLevel(logging.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enable sandbox debug logging\n",
        "os.environ['ASTRA_FORGE_SANDBOX_DEBUG'] = '1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a sandbox session (no DeepAgent conversation)\n",
        "Use the sandbox API directly without creating a DeepAgent conversation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sandbox session: f880696f-1c51-4ecd-b028-3d1119075d6a (workspace: /workspace)\n"
          ]
        }
      ],
      "source": [
        "from astraforge_toolkit import DeepAgentClient\n",
        "\n",
        "client = DeepAgentClient(base_url=BASE_URL, api_key=API_KEY)\n",
        "sandbox_session = client.create_sandbox_session()\n",
        "SANDBOX_SESSION_ID = sandbox_session.session_id\n",
        "print(f\"Sandbox session: {SANDBOX_SESSION_ID} (workspace: {sandbox_session.workspace_path})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload and read sandbox files\n",
        "Use the helper methods on `DeepAgentClient` to push a file into the sandbox and fetch it back.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload text (or bytes) to the sandbox workspace\n",
        "upload_result = client.upload_file(\n",
        "    SANDBOX_SESSION_ID,\n",
        "    \"/workspace/hello_from_notebook.txt\",\n",
        "    content=\"hello from the notebook!\\n\",\n",
        ")\n",
        "upload_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the file back; set encoding=None to get raw bytes\n",
        "downloaded = client.get_file_content(\n",
        "    SANDBOX_SESSION_ID,\n",
        "    \"/workspace/hello_from_notebook.txt\",\n",
        "    encoding=\"utf-8\",\n",
        ")\n",
        "print(downloaded)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a sandbox-backed DeepAgent (README quick start)\n",
        "This creates a DeepAgent conversation (separate from the standalone sandbox session above) and reuses its sandbox across tool calls.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install a model provider helper for the example (skip if already installed)\n",
        "%pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using DeepAgent conversation eacd793b-ae01-48f8-8372-956dc4ef3de4 and sandbox eacd793b-ae01-48f8-8372-956dc4ef3de4 for tool calls\n"
          ]
        }
      ],
      "source": [
        "from deepagents import create_deep_agent\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from astraforge_toolkit import (\n",
        "    SandboxBackend,\n",
        "    sandbox_shell,\n",
        "    sandbox_python_repl,\n",
        "    sandbox_open_url_with_playwright,\n",
        "    sandbox_view_image,\n",
        ")\n",
        "\n",
        "conv = client.create_conversation()\n",
        "AGENT_THREAD_ID = conv.conversation_id\n",
        "AGENT_SANDBOX_SESSION_ID = conv.sandbox_session_id\n",
        "print(f\"Using DeepAgent conversation {AGENT_THREAD_ID} and sandbox {AGENT_SANDBOX_SESSION_ID} for tool calls\")\n",
        "\n",
        "def backend_factory(rt):\n",
        "    return SandboxBackend(\n",
        "        rt,\n",
        "        base_url=BASE_URL,\n",
        "        api_key=API_KEY,\n",
        "        session_id=AGENT_SANDBOX_SESSION_ID,\n",
        "        # optional: session_params={\"image\": \"astraforge/codex-cli:latest\"},\n",
        "    )\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\")  # or any chat model you prefer\n",
        "tools = [\n",
        "    sandbox_shell,\n",
        "    sandbox_python_repl,\n",
        "    sandbox_open_url_with_playwright,\n",
        "    sandbox_view_image,\n",
        "]\n",
        "\n",
        "deep_agent = create_deep_agent(\n",
        "    model=model,\n",
        "    backend=backend_factory,\n",
        "    tools=tools,\n",
        ")\n",
        "\n",
        "RUN_CONFIG = {\n",
        "    \"thread_id\": AGENT_THREAD_ID,\n",
        "    \"configurable\": {\"sandbox_session_id\": AGENT_SANDBOX_SESSION_ID},\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deep_agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What tools i have ?\"}]},\n",
        "    config=RUN_CONFIG,\n",
        ")\n",
        "\n",
        "# Reuse RUN_CONFIG for follow-up calls to keep the same sandbox session and thread ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 16:40:26,090 DEBUG [astraforge_toolkit.backend] sandbox shell\n",
            "2025-12-03 16:40:26,249 DEBUG [astraforge_toolkit.backend] sandbox write failed: path=/main.py exit=2 stderr='' stdout='sh: 1: cannot create /main.py: Permission denied'\n",
            "2025-12-03 16:40:28,842 DEBUG [astraforge_toolkit.backend] sandbox shell\n",
            "2025-12-03 16:40:29,017 DEBUG [astraforge_toolkit.backend] sandbox write failed: path=/main.py exit=2 stderr='' stdout='sh: 1: cannot create /main.py: Permission denied'\n",
            "2025-12-03 16:40:30,965 DEBUG [astraforge_toolkit.backend] sandbox shell\n",
            "2025-12-03 16:40:31,101 DEBUG [astraforge_toolkit.backend] sandbox write failed: path=/main.py exit=2 stderr='' stdout='sh: 1: cannot create /main.py: Permission denied'\n",
            "2025-12-03 16:40:33,942 DEBUG [astraforge_toolkit.backend] sandbox shell\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='write a main.py that prints hello world', additional_kwargs={}, response_metadata={}, id='7846305d-3bf5-48b0-a451-b911703cc6d5'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 4508, 'total_tokens': 4535, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b547601dbd', 'id': 'chatcmpl-CijFnZ3KJjaPoZjF2Wjx1f1awIHT9', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--19498d5b-ecbb-4eba-9385-903cd6badc20-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': '/main.py', 'content': \"print('Hello, World!')\"}, 'id': 'call_5yr6toPKVGGMxLHuv668xMdZ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4508, 'output_tokens': 27, 'total_tokens': 4535, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='Write failed with exit code 2', name='write_file', id='91bc3663-a1ac-47f7-a243-e40c00df2317', tool_call_id='call_5yr6toPKVGGMxLHuv668xMdZ'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 4550, 'total_tokens': 4577, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4480}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b547601dbd', 'id': 'chatcmpl-CijFqVWor1NJEiFWNWhvY3hHkGhk7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--360dcd4b-db74-45bf-ad04-4a1abd98440e-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': '/main.py', 'content': 'print(\"Hello, World!\")'}, 'id': 'call_j4b6BsGUA4CR1cBodTywvPBP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4550, 'output_tokens': 27, 'total_tokens': 4577, 'input_token_details': {'audio': 0, 'cache_read': 4480}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='Write failed with exit code 2', name='write_file', id='0d4ccb11-d34f-47bc-8089-4b5d05fe98c0', tool_call_id='call_j4b6BsGUA4CR1cBodTywvPBP'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 4592, 'total_tokens': 4619, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4480}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b547601dbd', 'id': 'chatcmpl-CijFt3LgmT2y6rXVSkNfc53UvNMNA', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--19872a13-10d4-4851-835e-28aad43372ca-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': '/main.py', 'content': \"print('Hello, World!')\"}, 'id': 'call_XsPjoFBvAcrb9bRlDTWPJ2bY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4592, 'output_tokens': 27, 'total_tokens': 4619, 'input_token_details': {'audio': 0, 'cache_read': 4480}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='Write failed with exit code 2', name='write_file', id='04f3b8ac-7e0f-46ce-b9b4-7a2297d5c4e6', tool_call_id='call_XsPjoFBvAcrb9bRlDTWPJ2bY'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 4634, 'total_tokens': 4665, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_eca0ce8298', 'id': 'chatcmpl-CijFwi7VSYAn6IITZ3eGzB2GY1zy7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--cc61bd3f-726e-45b9-9818-9b5894f9cbb1-0', tool_calls=[{'name': 'sandbox_shell', 'args': {'command': 'echo \"print(\\'Hello, World!\\')\" > main.py', 'runtime': {}}, 'id': 'call_AHnu6o1CMRsBifT9TKIYpYJm', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4634, 'output_tokens': 31, 'total_tokens': 4665, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='$ cd /workspace && echo \"print(\\'Hello, World!\\')\" > main.py\\n(command exited with code 0 and produced no output)', name='sandbox_shell', id='2942e31c-6206-4488-8650-651203d34686', tool_call_id='call_AHnu6o1CMRsBifT9TKIYpYJm'),\n",
              "  AIMessage(content='I\\'ve successfully created a `main.py` file that contains the code to print \"Hello, World!\". Would you like to run this script now?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 4702, 'total_tokens': 4732, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4480}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b547601dbd', 'id': 'chatcmpl-CijFycDzIlRXbGhoYbIx5FpWPOBD5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--6f666e18-a473-452f-ab6b-25da20450b50-0', usage_metadata={'input_tokens': 4702, 'output_tokens': 30, 'total_tokens': 4732, 'input_token_details': {'audio': 0, 'cache_read': 4480}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = deep_agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"write a main.py that prints hello world\"}]},\n",
        "    config=RUN_CONFIG,\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
