#!/usr/bin/env python3
"""Thin wrapper that forwards to the official Codex CLI binary.

The global `@openai/codex` install drops a `codex` executable in `/usr/local/bin`.
This wrapper preserves developer conveniences that AstraForge relied upon in the
Python stub (for example `codex --spec foo.json`) while delegating the actual work
to the upstream CLI. It also guarantees a local `~/.codex/config.toml` exists so
the CLI can talk to the workspace-scoped LLM proxy without exposing the real API
key to the container.
"""

from __future__ import annotations

import json
import os
import shlex
import shutil
import subprocess
import sys
from pathlib import Path
from typing import Iterable, Sequence

_KNOWN_SUBCOMMANDS = {"exec", "login", "logout", "version", "resume"}
_REAL_CLI_ENV = "CODEX_REAL_CLI"
_DEFAULT_REAL_CLI = "/usr/local/bin/codex-real"
_CONFIG_DIR = Path.home() / ".codex"
_CONFIG_PATH = _CONFIG_DIR / "config.toml"
_DEFAULT_PROXY_ENV = "CODEX_WRAPPER_DEFAULT_PROXY_URL"
_DEFAULT_API_KEY_ENV = "CODEX_WRAPPER_API_KEY"
_DEFAULT_PROXY = (
    os.getenv(_DEFAULT_PROXY_ENV)
    or os.getenv("LLM_PROXY_URL")
    or "http://localhost:5200"
)
_DEFAULT_API_KEY = os.getenv(_DEFAULT_API_KEY_ENV, "sk-astraforge-stub")
_DEFAULT_MODEL = os.getenv("CODEX_WRAPPER_DEFAULT_MODEL", "gpt-5-codex")
_DEFAULT_PROVIDER_KEY = os.getenv(
    "CODEX_WRAPPER_MODEL_PROVIDER_KEY", "astraforge-proxy"
)
_DEFAULT_PROVIDER_NAME = os.getenv(
    "CODEX_WRAPPER_MODEL_PROVIDER_NAME", "AstraForge Proxy"
)
_DEFAULT_PROVIDER_WIRE_API = os.getenv(
    "CODEX_WRAPPER_MODEL_PROVIDER_WIRE_API", "responses"
)
_DEFAULT_PROVIDER_ENV_KEY = os.getenv(
    "CODEX_WRAPPER_PROVIDER_ENV_KEY", "ASTRAFORGE_PROXY_API_KEY"
)
_DEFAULT_REASONING_EFFORT = os.getenv("CODEX_WRAPPER_MODEL_REASONING_EFFORT", "high")
_DEFAULT_PROFILE = os.getenv("CODEX_WRAPPER_DEFAULT_PROFILE", "full_auto")


def _normalize_argv(argv: Sequence[str]) -> list[str]:
    if not argv:
        return list(argv)
    head = argv[0]
    if head in _KNOWN_SUBCOMMANDS:
        return list(argv)
    if head.startswith("-"):
        return ["exec", *argv]
    return list(argv)


def _convert_spec_flags(args: list[str]) -> list[str]:
    processed: list[str] = []
    i = 0
    while i < len(args):
        token = args[i]
        if token == "--spec":
            if i + 1 >= len(args):
                print(
                    "[codex-wrapper] Missing value for --spec flag.",
                    file=sys.stderr,
                    flush=True,
                )
                sys.exit(2)
            spec_value = args[i + 1]
            processed.extend(["-c", f"workspace.spec_path={json.dumps(spec_value)}"])
            i += 2
            continue
        if token.startswith("--spec="):
            _, spec_value = token.split("=", 1)
            processed.extend(["-c", f"workspace.spec_path={json.dumps(spec_value)}"])
            i += 1
            continue
        processed.append(token)
        i += 1
    return processed


def _has_profile_flag(args: Sequence[str]) -> bool:
    for token in args:
        if token in {"--profile", "-p"}:
            return True
        if token.startswith("--profile="):
            return True
    return False


def _extract_proxy_override(args: Iterable[str]) -> str | None:
    args_list = list(args)
    i = 0
    while i < len(args_list):
        token = args_list[i]
        if token in {"-c", "--config"} and i + 1 < len(args_list):
            candidate = args_list[i + 1]
            if "workspace.proxy_url=" in candidate:
                _, value = candidate.split("=", 1)
                try:
                    return json.loads(value)
                except json.JSONDecodeError:
                    return value
        i += 1
    return None


def _extract_config_override(args: Iterable[str], key: str) -> str | None:
    args_list = list(args)
    needle = f"{key}="
    i = 0
    while i < len(args_list):
        token = args_list[i]
        if token in {"-c", "--config"} and i + 1 < len(args_list):
            candidate = args_list[i + 1]
            if candidate.startswith(needle):
                _, raw = candidate.split("=", 1)
                try:
                    return json.loads(raw)
                except json.JSONDecodeError:
                    return raw
        i += 1
    return None


def _ensure_config(proxy_url: str) -> None:
    provider_key = _DEFAULT_PROVIDER_KEY
    provider_name = _DEFAULT_PROVIDER_NAME
    provider_wire_api = _DEFAULT_PROVIDER_WIRE_API
    provider_env_key = _DEFAULT_PROVIDER_ENV_KEY

    lines: list[str] = [
        "# Autogenerated by AstraForge Codex wrapper",
        "",
        f'model = "{_DEFAULT_MODEL}"',
        f'model_reasoning_effort = "{_DEFAULT_REASONING_EFFORT}"',
        f'profile = "{_DEFAULT_PROFILE}"',
        f'model_provider = "{provider_key}"',
        "",
        f"[model_providers.{provider_key}]",
        f'name = "{provider_name}"',
        f'base_url = "{proxy_url}"',
    ]
    if provider_env_key:
        lines.append(f'env_key = "{provider_env_key}"')
    if provider_wire_api:
        lines.append(f'wire_api = "{provider_wire_api}"')
    lines.extend(
        [
            "",
            f"[profiles.{_DEFAULT_PROFILE}]",
            'approval_policy = "never"',
            'sandbox_mode = "danger-full-access"',
            'model = "gpt-5-codex"',
            'history.persistence = "save-all"',
        ]
    )
    content = "\n".join(lines) + "\n"

    current = None
    if _CONFIG_PATH.exists():
        try:
            current = _CONFIG_PATH.read_text(encoding="utf-8")
        except OSError:
            current = None
    if current == content:
        return
    _CONFIG_DIR.mkdir(parents=True, exist_ok=True)
    _CONFIG_PATH.write_text(content, encoding="utf-8")


def _emit_config_preview() -> None:
    if not _CONFIG_PATH.exists():
        print("[codex-wrapper] config.toml not found after ensure step", flush=True)
        return
    try:
        raw = _CONFIG_PATH.read_text(encoding="utf-8")
    except OSError as exc:
        print(f"[codex-wrapper] failed to read config.toml: {exc}", flush=True)
        return
    print("[codex-wrapper] active config.toml:\n" + raw, flush=True)


def _resolve_real_cli() -> str:
    candidate = os.getenv(_REAL_CLI_ENV, _DEFAULT_REAL_CLI)
    if Path(candidate).is_file():
        return candidate
    # Fall back to PATH lookup for environments that rename differently.
    resolved = shutil.which(candidate) if "/" not in candidate else None
    if resolved:
        return resolved
    print(
        f"[codex-wrapper] Unable to locate real Codex CLI executable at '{candidate}'.",
        file=sys.stderr,
        flush=True,
    )
    sys.exit(127)


def main(argv: Sequence[str] | None = None) -> int:
    if argv is None:
        argv = sys.argv[1:]
    normalized = _normalize_argv(argv)
    rewritten = _convert_spec_flags(normalized)
    if not _has_profile_flag(rewritten):
        rewritten = ["--profile", _DEFAULT_PROFILE, *rewritten]
    proxy_override = _extract_proxy_override(rewritten)
    proxy_url = proxy_override or _DEFAULT_PROXY
    api_key_override = _extract_config_override(rewritten, "auth.api_key")
    api_key = (
        api_key_override
        if isinstance(api_key_override, str) and api_key_override
        else _DEFAULT_API_KEY
    )
    _ensure_config(proxy_url)
    _emit_config_preview()

    real_cli = _resolve_real_cli()
    command_display = shlex.join([real_cli, *rewritten])
    print(
        f"[codex-wrapper] delegating to {real_cli} via: {command_display}", flush=True
    )
    command = [real_cli, *rewritten]
    try:
        child_env = os.environ.copy()
        provider_env_key = _DEFAULT_PROVIDER_ENV_KEY
        if provider_env_key:
            child_env[provider_env_key] = api_key
        # Ensure standard OpenAI env vars fall back to the same key for compatibility.
        child_env["OPENAI_API_KEY"] = api_key
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            env=child_env,
        )
    except FileNotFoundError:
        print(
            "[codex-wrapper] Real Codex CLI executable is missing. Ensure `@openai/codex` is installed.",
            file=sys.stderr,
            flush=True,
        )
        return 127

    assert process.stdout is not None
    for line in process.stdout:
        print(f"[codex-real] {line.rstrip()}", flush=True)
    return process.wait()


if __name__ == "__main__":
    sys.exit(main())
